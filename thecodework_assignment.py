# -*- coding: utf-8 -*-
"""TheCodeWork_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XYPFZYM8BBit0CjVa2zEdtrXyjvZJVRY
"""

!pip install datasets transformers diffusers gradio

"""1. Load and Explore Dataset"""

from datasets import load_dataset

# Load the dataset
dataset = load_dataset("mrtoy/mobile-ui-design")

print(dataset['train'].column_names)
print(dataset['train'][0])

from datasets import load_dataset
import matplotlib.pyplot as plt

# Load the dataset
dataset = load_dataset("mrtoy/mobile-ui-design")

# Function to display the image
def display_image(image):
    plt.imshow(image)
    plt.axis('off')  # Hide axes
    plt.show()

# Display the first 3 images in the dataset
for i in range(3):
    img = dataset['train'][i]['image']
    print(f"Displaying image {i+1}")
    display_image(img)

"""2. Load Pre-trained models"""

from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from diffusers import StableDiffusionPipeline
import matplotlib.pyplot as plt
from PIL import Image

# Load LLM for text generation (GPT-Neo as an example)
model_name = "EleutherAI/gpt-neo-125M"
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Load Stable Diffusion for image generation
pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4").to("cuda")

"""3. Generate UI Design"""

def generate_design(query, num_images=3, guidance_scale=7.5, num_inference_steps=50):
    # Using LLM to generate text based on input
    nlp_model = pipeline('text-generation', model=model_name)
    generated_text = nlp_model(query, max_length=50)[0]['generated_text']
    print("Generated text description:", generated_text)

    # Generate multiple images using the generated text with Stable Diffusion
    images = []
    for i in range(num_images):
        generated_image = pipe(generated_text, guidance_scale=guidance_scale, num_inference_steps=num_inference_steps).images[0]
        images.append(generated_image)

    # Display all the generated images
    for idx, img in enumerate(images):
        plt.figure(figsize=(5, 5))
        plt.imshow(img)
        plt.axis('off')
        plt.title(f"Generated Image {idx + 1}")
        plt.show()

    return images

# Example query with multiple images
generate_design("A clean mobile login page with a modern design", num_images=3, guidance_scale=8.5, num_inference_steps=75)



"""Gradio UI"""

import gradio as gr

def generate_design(query):
    nlp_model = pipeline('text-generation', model=model_name)
    generated_text = nlp_model(query, max_length=50)[0]['generated_text']
    generated_image = pipe(generated_text).images[0]
    return generated_image

gr.Interface(fn=generate_design, inputs="text", outputs="image").launch()

import torch
print(torch.cuda.is_available())

